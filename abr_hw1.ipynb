{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymorphy2.tokenizers import simple_word_tokenize\n",
    "from gensim.summarization import keywords\n",
    "import summa\n",
    "import RAKE\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from unicodedata import normalize\n",
    "from nltk import everygrams\n",
    "from statistics import mean\n",
    "import yake\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание корпуса\n",
    "\n",
    "Для корпуса я взяла тексты новостей с хабра, в качестве ключевых слов были взяты теги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://habr.com/ru/news/t/587290/\n",
      "https://habr.com/ru/news/t/587284/\n",
      "https://habr.com/ru/news/t/587280/\n",
      "https://habr.com/ru/company/itsumma/news/t/587278/\n",
      "https://habr.com/ru/news/t/587268/\n",
      "https://habr.com/ru/news/t/587266/\n",
      "https://habr.com/ru/news/t/587258/\n",
      "https://habr.com/ru/news/t/587252/\n",
      "https://habr.com/ru/company/vk/news/t/587250/\n",
      "https://habr.com/ru/company/epam_systems/news/t/587244/\n",
      "https://habr.com/ru/company/etmc_exponenta/news/t/587232/\n",
      "https://habr.com/ru/news/t/587230/\n",
      "https://habr.com/ru/news/t/587210/\n",
      "https://habr.com/ru/news/t/587206/\n",
      "https://habr.com/ru/news/t/587202/\n",
      "https://habr.com/ru/news/t/587200/\n",
      "https://habr.com/ru/company/superjob/news/t/587196/\n",
      "https://habr.com/ru/news/t/587198/\n",
      "https://habr.com/ru/news/t/587188/\n",
      "https://habr.com/ru/news/t/587186/\n"
     ]
    }
   ],
   "source": [
    "lks = []\n",
    "resp = requests.get('https://habr.com/ru/news/').text\n",
    "soup = BeautifulSoup(resp, 'html.parser')\n",
    "news = soup.find_all('a', {'class': 'tm-article-snippet__title-link'})\n",
    "for nw in news:\n",
    "    lks.append('https://habr.com' + nw.get('href'))\n",
    "print('\\n'.join(lks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для сохранения использованных ссылок, чтобы не менялись тексты и подобранные к ним слова\n",
    "lks = ['https://habr.com/ru/news/t/587290/',\n",
    " 'https://habr.com/ru/news/t/587284/',\n",
    " 'https://habr.com/ru/news/t/587280/',\n",
    " 'https://habr.com/ru/company/itsumma/news/t/587278/',\n",
    " 'https://habr.com/ru/news/t/587268/',\n",
    " 'https://habr.com/ru/news/t/587266/',\n",
    " 'https://habr.com/ru/news/t/587258/',\n",
    " 'https://habr.com/ru/news/t/587252/',\n",
    " 'https://habr.com/ru/company/vk/news/t/587250/',\n",
    " 'https://habr.com/ru/company/epam_systems/news/t/587244/',\n",
    " 'https://habr.com/ru/company/etmc_exponenta/news/t/587232/',\n",
    " 'https://habr.com/ru/news/t/587230/',\n",
    " 'https://habr.com/ru/news/t/587210/',\n",
    " 'https://habr.com/ru/news/t/587206/',\n",
    " 'https://habr.com/ru/news/t/587202/',\n",
    " 'https://habr.com/ru/news/t/587200/',\n",
    " 'https://habr.com/ru/company/superjob/news/t/587196/',\n",
    " 'https://habr.com/ru/news/t/587198/',\n",
    " 'https://habr.com/ru/news/t/587188/',\n",
    " 'https://habr.com/ru/news/t/587186/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "kws = []\n",
    "for lnk in lks:\n",
    "    text = []\n",
    "    resp = requests.get(lnk).text\n",
    "    soup = BeautifulSoup(resp, 'html.parser')\n",
    "    article = soup.find('div', {'xmlns': 'http://www.w3.org/1999/xhtml'})\n",
    "    for tag in article.strings:\n",
    "        text.append(tag)\n",
    "    kw = soup.find_all('a', {'class': 'tm-tags-list__link'})\n",
    "    texts.append(normalize('NFKC', ' '.join(text)))\n",
    "    kws.append([normalize('NFKC', k.text) for k in kw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяю свои ключевые слова с уже выделенными. В большинстве своем они схожи, но появились некоторые новые. Еще изначальные ключевые слова иногда включают в себя какие-то с одной стороны, специфичные для области слова, но которые сложно назвать значимыми (например, в тексте про соцсети один раз перечисляются названия разных сетей, которые заблокировали и непонятно, можно ли их считать ключевыми). Я решила не исключать их, и посмотреть на объединение моих слов с выделенными на хабре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "mine_kws = []\n",
    "mine_kws.append(['Tesla', 'NHTSA', 'автопилот', 'обновление', 'электромобиль', 'ошибка'])\n",
    "mine_kws.append(['Meta AI', 'ReSkin', 'искусственный интеллект', 'кожа для роботов'])\n",
    "mine_kws.append(['Apple', 'Apple Fitness+', 'Apple Watch', 'тренировки'])\n",
    "mine_kws.append(['RP2040', 'микроконтроллер', 'Raspberry Pi', 'процессор', 'плата', 'Pico', 'Iono RP', 'чип'])\n",
    "mine_kws.append(['Узкомназорат', 'соцсети', 'социальные сети', 'ограничения'])\n",
    "mine_kws.append(['виртуальная «Тройка»', 'Тройка', 'Samsung Pay', 'фокус-группа', 'тестирование'])\n",
    "mine_kws.append(['конференция', 'NVIDIA GTC 2021', 'NVIDIA', 'метавселенная', 'искусственный интеллект'])\n",
    "mine_kws.append(['Telegram', 'обновление'])\n",
    "mine_kws.append(['веб-разработка', 'VK Team', 'трансляция'])\n",
    "mine_kws.append(['EPAM', 'ВТБ-Розничный бизнес', 'вебинар', 'Project Hiring Week'])\n",
    "\n",
    "for i in range(len(mine_kws)):\n",
    "    kws[i].extend(mine_kws[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лемматизируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MorphAnalyzer()\n",
    "def normalize_text(text):\n",
    "    lemmas = []\n",
    "    for t in simple_word_tokenize(text):\n",
    "        lemmas.append(m.parse(t)[0].normal_form)\n",
    "    return ' '.join(lemmas)\n",
    "\n",
    "corpus = [normalize_text(text) for text in texts]\n",
    "kws = [set([normalize_text(k) for k in kw]) for kw in kws]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, сколько токенов в текстах, чтобы уложиться в 3-5к знаков. В итоге возьмем 10 текстов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4142\n"
     ]
    }
   ],
   "source": [
    "l = 0\n",
    "for text in corpus[:10]:\n",
    "    l += len(text.split())\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[:10]\n",
    "kws = kws[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Выделение ключевых слов\n",
    "\n",
    "Методы: rake, text-rank и yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rake\n",
    "stop = stopwords.words('russian')\n",
    "rake = RAKE.Rake(stop)\n",
    "rake_kw = [set([i[0] for i in rake.run(text, minFrequency=1, maxWords=3) if i[1] > 0]) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text-rank\n",
    "trank_kw = [set([i[0] for i in summa.keywords.keywords(text, ratio=0.1, language='russian', additional_stopwords=stop, scores=True)]) for text in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "yk = yake.KeywordExtractor(lan='ru', n=1)#, dedupLim=deduplication_thresold, dedupFunc=deduplication_algo, windowsSize=windowSize)\n",
    "yake_kw = [set([i[0] for i in yk.extract_keywords(text)]) for text in corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фильтрация по шаблонам\n",
    "\n",
    "Для начала напишем функцию, которая размечает шаблоны для ключевых фраз. На выходе, помимо списка с фразами и шаблонами, также выдается все встретившиеся шаблоны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(kwds):\n",
    "    kws_pos = []\n",
    "    voc = []\n",
    "    for art in kwds:\n",
    "        artpos = []\n",
    "        for k in art:\n",
    "            kpos = []\n",
    "            for word in k.split(' '):\n",
    "                ps = str(m.parse(word)[0].tag.POS)\n",
    "                if ps == 'None':\n",
    "                    ps = str(m.parse(word)[0].tag)\n",
    "                kpos.append(ps)\n",
    "            artpos.append((k, kpos))\n",
    "            voc.append(' '.join(kpos))\n",
    "        kws_pos.append(artpos)\n",
    "    return kws_pos, Counter(voc)\n",
    "\n",
    "kw_pos = get_tags(kws)\n",
    "rake_pos = get_tags(rake_kw)\n",
    "trank_pos = get_tags(trank_kw)\n",
    "yake_pos = get_tags(yake_kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шаблоны изначально размеченных ключевых фраз. Большая часть ключевых слов состоит из одного слова - существительного или английского слова. Учитывая, что все тексты связаны с технологиями, это неудивительно, там много названий фирм/продуктов на английском.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'LATN': 28,\n",
       "         'NOUN': 38,\n",
       "         'NOUN NOUN': 1,\n",
       "         'LATN LATN': 11,\n",
       "         'NOUN PREP NOUN': 1,\n",
       "         'ADJF NOUN': 5,\n",
       "         'LATN UNKN': 1,\n",
       "         'LATN LATN UNKN': 1,\n",
       "         'PNCT NOUN PNCT': 2,\n",
       "         'ADJF PNCT INFN UNKN UNKN PNCT': 1,\n",
       "         'LATN LATN NUMB,intg': 1,\n",
       "         'LATN LATN LATN': 2,\n",
       "         'ADJF UNKN NOUN': 1})"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kw_pos[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, которая фильтрует ключевые фразы по шаблону"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_kw(kwd_ps, templ):\n",
    "    fil_art = []\n",
    "    for art in kwd_ps[0]:\n",
    "        fil_k = []\n",
    "        for k in art:\n",
    "            if k[1] == templ:\n",
    "                fil_k.append(k[0])\n",
    "        fil_art.append(set(fil_k))\n",
    "    return fil_art"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подсчет метрик "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(pred_kws, name, filt=''):\n",
    "    if filt != '':\n",
    "        pred_kws = filter_kw(pred_kws, filt)\n",
    "        true_kws = filter_kw(kw_pos, filt)\n",
    "    else:\n",
    "        true_kws = kws\n",
    "    precision = [len(kw & pred_kw)/len(pred_kw) if len(pred_kw) != 0 else 0 for kw, pred_kw in zip(true_kws, pred_kws) if len(kw) != 0]\n",
    "    recall = [len(kw & pred_kw)/len(kw) for kw, pred_kw in zip(true_kws, pred_kws) if len(kw) != 0]\n",
    "    fscore = [2*pr*rcl/(pr + rcl)  if pr + rcl != 0 else 0 for pr, rcl in zip(precision, recall)]\n",
    "    if mean(recall) + mean(fscore) + mean(precision) != 0:\n",
    "        print(name + ' ' + ' '.join(filt))\n",
    "        if filt == '':\n",
    "            print('\\n'.join(['Ключевые слова: ' + ', '.join(true_k) + '\\nНайдено: ' + ', '.join(true_k & pred_k) for true_k, pred_k in zip(true_kws, pred_kws)]))\n",
    "        print('Precision: ' + str(mean(precision)) +'\\nRecall: ' + str(mean(recall)) + '\\nF-score: ' + str(mean(fscore)) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики без фильтров. Итоги.\n",
    "\n",
    "1) Rake предсказывает слишком много ненужного и из-за этого очень снижается точность. Однако это помогает с полнотой, она у него лучшая среди всех моделей. Я пробовала отфильтровывать слова по их итоговому скору (брать, например, те, у кого скор > 4, но это улучшение точности незначительно и не оправдывает ухудшение полноты). В целом можно сказать, что это худшая из моделей.\n",
    "\n",
    "2) TextRank дает лучшую точность и худшую полноту (из-за установленного ratio предсказывает меньше слов, чем другие модели, и поэтому получается лучшая точность, но худшая полнота). Их соотношение можно немного поменять, изменив ratio в модели, однако я остановилась на этом, т.к. он показался лучшим. Ф-скор примерно такой же, как и у yake. \n",
    "\n",
    "3) Yake. Пожалуй, лучшая из моделей, она не так сильно отстает от rake по полноте, а от textrank - по точности. Однако у нее есть небольшая особенность - она предсказывает только ключевые фразы, состоящие из одного слова. Если ставить максимальное количество слов в фразе выше, то модель в основном выдает фразы именно этой длины, но большинство ключевых фраз у нас состоит из одного слова, и поэтому результат получается очень плохой. Получается, этот, на первый взгляд, недостаток, в итоге становится ее преимуществом, потому что одна из основных проблем других моделей -  предсказание большого количесвта лишних фраз, длиной больше 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rake \n",
      "Ключевые слова: nhtsa, автопилот, автопилот автомобиль, электромобиль, tesla, обновление, full-self driving, ошибка\n",
      "Найдено: обновление, nhtsa, автопилот\n",
      "Ключевые слова: кожа для робот, искусственный интеллект, искусственный кожа, робот, meta ai, reskin\n",
      "Найдено: meta ai, робот, искусственный интеллект\n",
      "Ключевые слова: здоровье, apple watch, фитнес, ios, fitness +, apple fitness +, apple, тренировка, apple one\n",
      "Найдено: apple watch, fitness +, тренировка, apple\n",
      "Ключевые слова: arduino, микроконтроллер, pico, iono rp, pimoroni, чип, adafruit, rp2040, процессор, плат, raspberry pi, sparkfun\n",
      "Найдено: pimoroni, arduino, sparkfun\n",
      "Ключевые слова: tiktok, twitter, ограничение, узбекистан, блокировка, соцсеть, « вконтакте », замедление, skype, youtube, социальный сеть, « одноклассник », facebook, instagram, telegram, узкомназорат\n",
      "Найдено: tiktok, « вконтакте », youtube, skype, « одноклассник », facebook, instagram, twitter\n",
      "Ключевые слова: тестирование, мосметро, транспортный карта, тройка, samsung pay, москва, samsung, виртуальный « троить ̆ ка », фокус-группа, android, транспорт\n",
      "Найдено: мосметро, samsung, фокус-группа\n",
      "Ключевые слова: искусственный интеллект, конференция, метавселенная, nvidia, анонс, ия, nvidia gtc 2021\n",
      "Найдено: ия, метавселенная, nvidia\n",
      "Ключевые слова: телеграм, ios, обновление, android, telegram\n",
      "Найдено: ios, android\n",
      "Ключевые слова: фронтенд-разработка, веб-разработа, delivery club, веб-разработка, вконтакте, трансляция, митапа, web vitals, vk team, vk, почта, vk mini apps, frontend\n",
      "Найдено: delivery club, веб-разработка\n",
      "Ключевые слова: hiring week, вебинар, project hiring week, vtb, втб-розничный ̆ бизнес, epam\n",
      "Найдено: вебинар, project hiring week\n",
      "Precision: 0.05084654658608954\n",
      "Recall: 0.3657922632922633\n",
      "F-score: 0.08475200767299489\n",
      "\n",
      "TextRank \n",
      "Ключевые слова: nhtsa, автопилот, автопилот автомобиль, электромобиль, tesla, обновление, full-self driving, ошибка\n",
      "Найдено: nhtsa, электромобиль, tesla, обновление, ошибка\n",
      "Ключевые слова: кожа для робот, искусственный интеллект, искусственный кожа, робот, meta ai, reskin\n",
      "Найдено: reskin\n",
      "Ключевые слова: здоровье, apple watch, фитнес, ios, fitness +, apple fitness +, apple, тренировка, apple one\n",
      "Найдено: apple, тренировка\n",
      "Ключевые слова: arduino, микроконтроллер, pico, iono rp, pimoroni, чип, adafruit, rp2040, процессор, плат, raspberry pi, sparkfun\n",
      "Найдено: pico, плат, raspberry pi, arduino\n",
      "Ключевые слова: tiktok, twitter, ограничение, узбекистан, блокировка, соцсеть, « вконтакте », замедление, skype, youtube, социальный сеть, « одноклассник », facebook, instagram, telegram, узкомназорат\n",
      "Найдено: узбекистан, соцсеть, узкомназорат\n",
      "Ключевые слова: тестирование, мосметро, транспортный карта, тройка, samsung pay, москва, samsung, виртуальный « троить ̆ ка », фокус-группа, android, транспорт\n",
      "Найдено: мосметро, тестирование, samsung\n",
      "Ключевые слова: искусственный интеллект, конференция, метавселенная, nvidia, анонс, ия, nvidia gtc 2021\n",
      "Найдено: ия\n",
      "Ключевые слова: телеграм, ios, обновление, android, telegram\n",
      "Найдено: ios\n",
      "Ключевые слова: фронтенд-разработка, веб-разработа, delivery club, веб-разработка, вконтакте, трансляция, митапа, web vitals, vk team, vk, почта, vk mini apps, frontend\n",
      "Найдено: трансляция, вконтакте\n",
      "Ключевые слова: hiring week, вебинар, project hiring week, vtb, втб-розничный ̆ бизнес, epam\n",
      "Найдено: epam\n",
      "Precision: 0.18297775324091115\n",
      "Recall: 0.24708194583194582\n",
      "F-score: 0.19661409921015582\n",
      "\n",
      "Yake \n",
      "Ключевые слова: nhtsa, автопилот, автопилот автомобиль, электромобиль, tesla, обновление, full-self driving, ошибка\n",
      "Найдено: nhtsa, электромобиль, tesla, обновление, ошибка\n",
      "Ключевые слова: кожа для робот, искусственный интеллект, искусственный кожа, робот, meta ai, reskin\n",
      "Найдено: reskin, робот\n",
      "Ключевые слова: здоровье, apple watch, фитнес, ios, fitness +, apple fitness +, apple, тренировка, apple one\n",
      "Найдено: apple, тренировка\n",
      "Ключевые слова: arduino, микроконтроллер, pico, iono rp, pimoroni, чип, adafruit, rp2040, процессор, плат, raspberry pi, sparkfun\n",
      "Найдено: микроконтроллер, pico, чип, arduino\n",
      "Ключевые слова: tiktok, twitter, ограничение, узбекистан, блокировка, соцсеть, « вконтакте », замедление, skype, youtube, социальный сеть, « одноклассник », facebook, instagram, telegram, узкомназорат\n",
      "Найдено: ограничение, узбекистан, соцсеть, facebook, узкомназорат\n",
      "Ключевые слова: тестирование, мосметро, транспортный карта, тройка, samsung pay, москва, samsung, виртуальный « троить ̆ ка », фокус-группа, android, транспорт\n",
      "Найдено: тестирование, мосметро, тройка, samsung, фокус-группа\n",
      "Ключевые слова: искусственный интеллект, конференция, метавселенная, nvidia, анонс, ия, nvidia gtc 2021\n",
      "Найдено: метавселенная, nvidia, конференция\n",
      "Ключевые слова: телеграм, ios, обновление, android, telegram\n",
      "Найдено: ios\n",
      "Ключевые слова: фронтенд-разработка, веб-разработа, delivery club, веб-разработка, вконтакте, трансляция, митапа, web vitals, vk team, vk, почта, vk mini apps, frontend\n",
      "Найдено: трансляция, почта, вконтакте\n",
      "Ключевые слова: hiring week, вебинар, project hiring week, vtb, втб-розничный ̆ бизнес, epam\n",
      "Найдено: \n",
      "Precision: 0.15\n",
      "Recall: 0.31402750027750026\n",
      "F-score: 0.19833188724512418\n",
      "\n"
     ]
    }
   ],
   "source": [
    "calc_metrics(rake_kw, 'Rake')\n",
    "calc_metrics(trank_kw, 'TextRank')\n",
    "calc_metrics(yake_kw, 'Yake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики с фильтрацией.\n",
    "\n",
    "Добавление фильтрации явно немного улучшает результаты, можно заметить, что особенно хороши показатели для LATN по сравнению с другими, а это один из двух самых распространенных шаблонов. Самый распространенный шаблон - NOUN, дает примерно такие же результаты, как и модели без фильтрации, но они везде немного улучшены. Можно заметить, что Yake и TextRank очень плохо справляются с предсказанием фраз длиной больше 1, у них совпадений вообще практически нет (ниже выведены только те шаблоны, результат для которых больше 0, то есть есть хотя бы одно совпадение в какм-нибудь из текстов). Rake в этом плане несколько лучше, он предсказывает 7 из имеющихся 13 шаблонов, однако и он покрывает не все."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rake LATN\n",
      "Precision: 0.3214285714285714\n",
      "Recall: 0.4523809523809524\n",
      "F-score: 0.32702741702741706\n",
      "\n",
      "Rake NOUN\n",
      "Precision: 0.08625522138680033\n",
      "Recall: 0.38095238095238093\n",
      "F-score: 0.12159376571141277\n",
      "\n",
      "Rake LATN LATN\n",
      "Precision: 0.35714285714285715\n",
      "Recall: 0.2619047619047619\n",
      "F-score: 0.2857142857142857\n",
      "\n",
      "Rake ADJF NOUN\n",
      "Precision: 0.041666666666666664\n",
      "Recall: 0.125\n",
      "F-score: 0.0625\n",
      "\n",
      "Rake LATN UNKN\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-score: 1.0\n",
      "\n",
      "Rake PNCT NOUN PNCT\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F-score: 1.0\n",
      "\n",
      "Rake LATN LATN LATN\n",
      "Precision: 0.5\n",
      "Recall: 0.5\n",
      "F-score: 0.5\n",
      "\n",
      "TextRank LATN\n",
      "Precision: 0.475\n",
      "Recall: 0.4166666666666667\n",
      "F-score: 0.41000000000000003\n",
      "\n",
      "TextRank NOUN\n",
      "Precision: 0.17924603174603174\n",
      "Recall: 0.2702380952380952\n",
      "F-score: 0.20598068598068597\n",
      "\n",
      "TextRank LATN LATN\n",
      "Precision: 0.14285714285714285\n",
      "Recall: 0.07142857142857142\n",
      "F-score: 0.09523809523809523\n",
      "\n",
      "Yake LATN\n",
      "Precision: 0.4369047619047619\n",
      "Recall: 0.48095238095238096\n",
      "F-score: 0.37243589743589745\n",
      "\n",
      "Yake NOUN\n",
      "Precision: 0.1714979464979465\n",
      "Recall: 0.4845238095238095\n",
      "F-score: 0.2408229189111542\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for meth in [(rake_pos, 'Rake'), (trank_pos, 'TextRank'), (yake_pos, 'Yake')]:\n",
    "    for filt in kw_pos[1]:\n",
    "        calc_metrics(*meth, filt.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Методы решения проблем:\n",
    "\n",
    "1) Для Yake можно попробовать объединить результаты, которые он выдает для 1, 2 и 3 слов, но тогда нужно как-то решить, в каком соотношении их добавлять, потому что если добавить все, то получится ситуация, как с rake.\n",
    "\n",
    "2) Для всех моделей: сохранить соотношение кол-ва фраз, состоящих из 1, 2 и 3 слов, поскольку между ними есть явная разница, и большое кол-во предсказанных длинных фраз сильно ухудшает качество.\n",
    "\n",
    "3) Улучшить морф. разметку и придумать, что делать с синонимами/транслитерацией/сокращениями. Это особенно важно для текстов, в которых есть иностранные названия, потому что можно часто встретить в одном тексте, например, VK/вк/Вконтакте. Допустим, они встретились все по одному разу, не хочется учитывать их как отдельные ключевые слова, поэтому можно, например, заменять их все на один какой-то вариант в текстах, чтобы их значимость повышалась."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
